name: chatbot
services:
  db:
    image: timescale/timescaledb-ha:pg16
    environment:
      POSTGRES_PASSWORD: postgres
    ports:
      - "5434:5432"
    volumes:
      - ./data/db:/var/lib/postgresql/data
  storage:
    image: quay.io/minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: password
    volumes:
      - ./data/minio:/data
    command: server /data --console-address ":9001"
  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    ports:
      - "8080:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=http://localhost:8080/
    restart: unless-stopped
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    ports:
      - "11434:8000"  # Map to Ollama's port for easy replacement
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
    command: >
      --model meta-llama/Meta-Llama-3.1-8B-Instruct
      --tool-call-parser llama3_json
      --chat-template /vllm-workspace/examples/tool_chat_template_llama3_json.jinja
      --host 0.0.0.0
      --port 8000
      --gpu-memory-utilization 0.7
      --max-model-len 8192
      --dtype auto
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: '4gb'
    restart: unless-stopped
  vllm-embeddings:
    image: vllm/vllm-openai:latest
    container_name: vllm-embeddings
    ports:
      - "11435:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
    command: >
      --model BAAI/bge-small-en-v1.5
      --host 0.0.0.0
      --port 8000
      --gpu-memory-utilization 0.3
      --dtype auto
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: '2gb'
    restart: unless-stopped
