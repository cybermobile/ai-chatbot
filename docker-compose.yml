name: chatbot
services:
  db:
    image: timescale/timescaledb-ha:pg16
    environment:
      POSTGRES_PASSWORD: postgres
    ports:
      - "5434:5432"
    volumes:
      - ./data/db:/var/lib/postgresql/data
  storage:
    image: quay.io/minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: SPX9PsPwUzJzNcRHRn+RxKDJmnO515TukfKVBotfhng=
    volumes:
      - ./data/minio:/data
    command: server /data --console-address ":9001"
  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    ports:
      - "8081:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=http://localhost:8081/
    restart: unless-stopped
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    ports:
      - "11436:8000"  # vLLM main inference port
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
    command: >
      --model hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4
      --quantization awq
      --dtype auto
      --enable-auto-tool-choice
      --tool-call-parser llama3_json
      --host 0.0.0.0
      --port 8000
      --gpu-memory-utilization 0.8
      --max-model-len 8192
      --max-num-seqs 4
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: '4gb'
    restart: unless-stopped
  # embeddings:
  #   image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
  #   container_name: embeddings
  #   ports:
  #     - "11435:80"
  #   volumes:
  #     - ~/.cache/huggingface:/data
  #   environment:
  #     - MODEL_ID=BAAI/bge-small-en-v1.5
  #     - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
  #   command: --model-id BAAI/bge-small-en-v1.5 --port 80
  #   restart: unless-stopped
