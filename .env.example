# Generate a random secret: `openssl rand -base64 32`
AUTH_SECRET=****

# Instructions to create a database here: https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md
# For local development with docker-compose: postgresql://postgres:postgres@localhost:5434/postgres
# NOTE: Database must have pgvector extension enabled. TimescaleDB includes this by default.
POSTGRES_URL=****

# Instructions to create a MinIO instance here: https://min.io/docs/minio/container/administration/console/security-and-access.html#minio-console-user-access-keys
# For local development with docker-compose, use these values:
MINIO_URL=localhost
MINIO_PORT=9000
MINIO_ACCESS_KEY=minio
MINIO_SECRET_KEY=password
MINIO_BUCKET=resources

# next-auth trust host
NEXTAUTH_URL=http://localhost:3000
AUTH_TRUST_HOST=http://localhost:3000

# LLM Inference Backend (vLLM or Ollama)
# For vLLM (recommended for Linux with GPU): http://127.0.0.1:11434
# For Ollama (Mac): http://127.0.0.1:11434
LLM_BASE_URL=http://127.0.0.1:11434
LLM_PROVIDER=vllm  # Options: vllm, ollama

# vLLM Embedding Server (Linux with GPU)
VLLM_EMBEDDING_URL=http://127.0.0.1:11435
VLLM_EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# Ollama configuration (Mac only, fallback)
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Optional: HuggingFace token for gated models (Llama, etc.)
HF_TOKEN=

# SearXNG web search (optional, defaults to localhost:8080)
SEARXNG_URL=http://localhost:8080